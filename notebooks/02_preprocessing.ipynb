{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f2e7eb-33ca-4475-bff7-093c730f7360",
   "metadata": {},
   "source": [
    "# ðŸ“Š PISA 2022 UK Data Preprocessing for Tree-Based Models\n",
    "\n",
    "This notebook prepares the **PISA 2022 UK dataset** for training tree-based machine learning models, specifically **Decision Trees**, **Random Forests**, and **XGBoost**. The preprocessing steps are tailored to suit these models, which do not require feature scaling but handle categorical and missing data in specific ways.\n",
    "\n",
    "### ðŸ”§ Key Steps:\n",
    "1. **Reverse-Code Selected Variables** â€“ Adjusts the scale of items where higher values originally indicated more negative outcomes.\n",
    "2. **Binary Variable Creation** â€“ Recodes key categorical variables (e.g., gender, computer access) into binary format.\n",
    "3. **Variable Renaming** â€“ Renames columns with meaningful, interpretable names across categories (e.g., individual, academic, family, school, peer/social, contextual).\n",
    "4. **Missing Data Handling**  \n",
    "   - Drops variables with >30% missing values.  \n",
    "   - Drops rows missing the target variable (`math_1`).  \n",
    "   - Uses **median imputation** for numeric features and **mode imputation** for binary/categorical features.\n",
    "5. **Data Splitting** â€“ Splits the dataset into training, validation, and test sets (60/20/20 split).\n",
    "6. **One-Hot Encoding** â€“ Applies to the `region` variable and aligns encoded columns across all datasets.\n",
    "7. **Export Clean Data** â€“ Saves preprocessed training, validation, and test sets to CSV files for downstream modeling.\n",
    "\n",
    "> **Note:** Exploratory Data Analysis (EDA) was conducted separately and is not included in this notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a0901-9f95-48dc-ac47-94b94a3bb0b9",
   "metadata": {},
   "source": [
    "# 0. Import libraries and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda13810-1246-4885-a858-904023bab0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166dfabe-c530-4150-9e64-eea29a0fe5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/workspaces/mini_project_2/data/pisa_2022_uk_selected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b4c372-7d6b-4d46-a06c-085b9e7a29f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CNTSTUID</th>\n",
       "      <th>W_FSTUWT</th>\n",
       "      <th>PV1MATH</th>\n",
       "      <th>PV2MATH</th>\n",
       "      <th>PV3MATH</th>\n",
       "      <th>PV4MATH</th>\n",
       "      <th>PV5MATH</th>\n",
       "      <th>PV6MATH</th>\n",
       "      <th>PV7MATH</th>\n",
       "      <th>PV8MATH</th>\n",
       "      <th>...</th>\n",
       "      <th>ST270Q02JA</th>\n",
       "      <th>ST038Q05NA</th>\n",
       "      <th>ST265Q03JA</th>\n",
       "      <th>ST272Q01JA</th>\n",
       "      <th>ST034Q02TA</th>\n",
       "      <th>ST038Q03NA</th>\n",
       "      <th>ST038Q04NA</th>\n",
       "      <th>ST315Q04JA</th>\n",
       "      <th>ST315Q06JA</th>\n",
       "      <th>REGION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82600003.0</td>\n",
       "      <td>4.77923</td>\n",
       "      <td>699.809</td>\n",
       "      <td>598.369</td>\n",
       "      <td>593.952</td>\n",
       "      <td>603.361</td>\n",
       "      <td>666.143</td>\n",
       "      <td>635.207</td>\n",
       "      <td>608.553</td>\n",
       "      <td>583.002</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82600004.0</td>\n",
       "      <td>8.23968</td>\n",
       "      <td>454.479</td>\n",
       "      <td>377.041</td>\n",
       "      <td>463.036</td>\n",
       "      <td>394.994</td>\n",
       "      <td>396.957</td>\n",
       "      <td>429.649</td>\n",
       "      <td>459.601</td>\n",
       "      <td>439.692</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82600005.0</td>\n",
       "      <td>136.31080</td>\n",
       "      <td>566.143</td>\n",
       "      <td>616.946</td>\n",
       "      <td>556.976</td>\n",
       "      <td>656.532</td>\n",
       "      <td>652.062</td>\n",
       "      <td>611.077</td>\n",
       "      <td>657.387</td>\n",
       "      <td>645.288</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82600006.0</td>\n",
       "      <td>84.42297</td>\n",
       "      <td>371.820</td>\n",
       "      <td>357.674</td>\n",
       "      <td>264.029</td>\n",
       "      <td>393.236</td>\n",
       "      <td>361.008</td>\n",
       "      <td>326.822</td>\n",
       "      <td>390.370</td>\n",
       "      <td>338.591</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82611.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82600007.0</td>\n",
       "      <td>110.62140</td>\n",
       "      <td>423.607</td>\n",
       "      <td>382.887</td>\n",
       "      <td>414.527</td>\n",
       "      <td>404.693</td>\n",
       "      <td>388.663</td>\n",
       "      <td>427.517</td>\n",
       "      <td>447.633</td>\n",
       "      <td>445.616</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>82611.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CNTSTUID   W_FSTUWT  PV1MATH  PV2MATH  PV3MATH  PV4MATH  PV5MATH  \\\n",
       "0  82600003.0    4.77923  699.809  598.369  593.952  603.361  666.143   \n",
       "1  82600004.0    8.23968  454.479  377.041  463.036  394.994  396.957   \n",
       "2  82600005.0  136.31080  566.143  616.946  556.976  656.532  652.062   \n",
       "3  82600006.0   84.42297  371.820  357.674  264.029  393.236  361.008   \n",
       "4  82600007.0  110.62140  423.607  382.887  414.527  404.693  388.663   \n",
       "\n",
       "   PV6MATH  PV7MATH  PV8MATH  ...  ST270Q02JA  ST038Q05NA  ST265Q03JA  \\\n",
       "0  635.207  608.553  583.002  ...         4.0         1.0         1.0   \n",
       "1  429.649  459.601  439.692  ...         1.0         1.0         2.0   \n",
       "2  611.077  657.387  645.288  ...         1.0         1.0         1.0   \n",
       "3  326.822  390.370  338.591  ...         3.0         1.0         2.0   \n",
       "4  427.517  447.633  445.616  ...         2.0         1.0         1.0   \n",
       "\n",
       "   ST272Q01JA  ST034Q02TA  ST038Q03NA  ST038Q04NA  ST315Q04JA  ST315Q06JA  \\\n",
       "0         4.0         NaN         1.0         1.0         NaN         NaN   \n",
       "1         8.0         2.0         2.0         2.0         NaN         NaN   \n",
       "2        10.0         2.0         1.0         1.0         4.0         3.0   \n",
       "3         1.0         2.0         1.0         1.0         3.0         NaN   \n",
       "4         8.0         1.0         2.0         2.0         NaN         4.0   \n",
       "\n",
       "    REGION  \n",
       "0  82613.0  \n",
       "1  82612.0  \n",
       "2  82611.0  \n",
       "3  82611.0  \n",
       "4  82611.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508db47-f3e0-4900-8245-b1feab493e5e",
   "metadata": {},
   "source": [
    "## 1. Recode variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797e36a4-0ce8-4389-9e41-9c17336fd173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-coded variables with their original scales\n",
    "# Format: \"VARIABLE_NAME\": (min_value, max_value)\n",
    "reverse_vars = {\n",
    "    \"ST309Q02JA\": (1, 5),  # not_distract: 1â€“5\n",
    "    \"ST258Q01JA\": (1, 5),  # food_sec: 1â€“5\n",
    "    \"ST034Q03TA\": (1, 4),  # schl_belong: 1â€“4\n",
    "    \"ST270Q02JA\": (1, 4),  # teacher_help: 1â€“4\n",
    "    \"ST038Q05NA\": (1, 4),  # safe_student: 1â€“4\n",
    "    \"ST265Q03JA\": (1, 4),  # safe_class: 1â€“4\n",
    "    \"ST034Q02TA\": (1, 4),  # make_friends: 1â€“4\n",
    "    \"ST038Q03NA\": (1, 4),  # feel_included: 1â€“4\n",
    "    \"ST038Q04NA\": (1, 4)   # no_mock: 1â€“4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03d00b9-0f0d-4fad-8525-578b9099a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_code(df, reverse_map):\n",
    "    df = df.copy()\n",
    "    for var, (min_val, max_val) in reverse_map.items():\n",
    "        if var in df.columns:\n",
    "            df[var] = max_val + min_val - df[var]\n",
    "    return df\n",
    "\n",
    "df = reverse_code(df, reverse_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3b021-8d3a-4a15-adc6-93cab8a3dc83",
   "metadata": {},
   "source": [
    "## 2. Create Binary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49b95c1-d01c-4dc8-9c1f-b5cd1d91a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ST004D01T\"] = df[\"ST004D01T\"].apply(lambda x: 1 if x == 1 else 0 if x == 2 else np.nan)  # gender\n",
    "df[\"ST327Q06JA\"] = df[\"ST327Q06JA\"].apply(lambda x: 1 if x == 1 else 0 if x == 2 else np.nan)  # expt_bach\n",
    "df[\"ST250Q02JA\"] = df[\"ST250Q02JA\"].apply(lambda x: 1 if x == 1 else 0 if x == 2 else np.nan)  # has_computer\n",
    "df[\"ST255Q01JA\"] = df[\"ST255Q01JA\"].apply(lambda x: 1 if x == 1 else 0 if x in [2,3,4,5,6,7] else np.nan)  # has_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69331431-cd06-44c1-91a9-3453843a2f7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST004D01T</th>\n",
       "      <th>ST327Q06JA</th>\n",
       "      <th>ST250Q02JA</th>\n",
       "      <th>ST255Q01JA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST004D01T  ST327Q06JA  ST250Q02JA  ST255Q01JA\n",
       "0          0         1.0         1.0         0.0\n",
       "1          0         0.0         1.0         0.0\n",
       "2          0         1.0         1.0         0.0\n",
       "3          1         NaN         0.0         0.0\n",
       "4          0         NaN         1.0         0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"ST004D01T\", \"ST327Q06JA\", \"ST250Q02JA\", \"ST255Q01JA\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb6a439-cac3-49f3-8737-bae7c5c7e8cd",
   "metadata": {},
   "source": [
    "## 3. Rename variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f772a7c-c008-4103-948b-5dfdbc5b91c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core renaming dictionary\n",
    "rename_dict = {\n",
    "    # Individual\n",
    "    \"ST004D01T\": \"gender\",\n",
    "    \"ST016Q01NA\": \"life_sat\",\n",
    "    \"ST313Q01JA\": \"emo_control\",\n",
    "    \"ST309Q02JA\": \"not_distract\",\n",
    "    \"ST301Q01JA\": \"curiosity\",\n",
    "    \"ST305Q01JA\": \"comfort_lead\",\n",
    "\n",
    "    # Academic\n",
    "    \"ST296Q01JA\": \"math_hwork\",\n",
    "    \"ST293Q03JA\": \"math_effort\",\n",
    "    \"ST292Q01JA\": \"math_conf\",\n",
    "    \"ST327Q06JA\": \"expt_bach\",\n",
    "    \"ST355Q05JA\": \"conf_self_mot\",\n",
    "\n",
    "    # Family\n",
    "    \"ESCS\": \"SES\",\n",
    "    \"ST230Q01JA\": \"num_sib\",\n",
    "    \"ST258Q01JA\": \"food_sec\",\n",
    "    \"ST259Q01JA\": \"family_stat\",\n",
    "    \"ST300Q01JA\": \"parent_talk_schl\",\n",
    "    \"ST300Q02JA\": \"parent_eat_with\",\n",
    "    \"ST250Q02JA\": \"has_computer\",\n",
    "    \"ST255Q01JA\": \"has_books\",\n",
    "\n",
    "    # School\n",
    "    \"ST034Q03TA\": \"schl_belong\",\n",
    "    \"ST267Q01JA\": \"teach_respect\",\n",
    "    \"ST267Q05JA\": \"teac_interest\",\n",
    "    \"ST273Q01JA\": \"listen_teacher\",\n",
    "    \"ST285Q04JA\": \"teacher_explain\",\n",
    "    \"ST270Q02JA\": \"teacher_help\",\n",
    "    \"ST038Q05NA\": \"safe_student\",\n",
    "    \"ST265Q03JA\": \"safe_class\",\n",
    "    \"ST272Q01JA\": \"qual_math_instruct\",\n",
    "\n",
    "    # Peer/Social\n",
    "    \"ST034Q02TA\": \"make_friends\",\n",
    "    \"ST038Q03NA\": \"feel_included\",\n",
    "    \"ST038Q04NA\": \"no_mock\",\n",
    "    \"ST315Q04JA\": \"trust_friends\",\n",
    "    \"ST315Q06JA\": \"trust_gen\",\n",
    "\n",
    "    # Contextual\n",
    "    \"REGION\": \"region\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c77ce4-5eeb-4c79-a834-c17b39c4e7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add PV renaming (PV1MATH â†’ math_1, PV1READ â†’ read_1, etc.)\n",
    "for subject in [\"MATH\", \"READ\", \"SCIE\"]:\n",
    "    for i in range(1, 11):\n",
    "        old = f\"PV{i}{subject}\"\n",
    "        new = f\"{subject.lower()}_{i}\"\n",
    "        rename_dict[old] = new\n",
    "df.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c270acc-378f-4094-b4cf-971dc7683404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map region codes \n",
    "region_map = {\n",
    "    82611: \"england\",\n",
    "    82612: \"n_ireland\",\n",
    "    82613: \"wales\",\n",
    "    82620: \"scotland\"\n",
    "}\n",
    "\n",
    "df[\"region\"] = df[\"region\"].map(region_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "715dff74-f868-49be-9eff-6b96ec9519f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math_binary\n",
      "1    6486\n",
      "0    6486\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create binary target from math_1 using the median\n",
    "math_median = df[\"math_1\"].median()\n",
    "df[\"math_binary\"] = df[\"math_1\"].apply(lambda x: 1 if x >= math_median else 0)\n",
    "\n",
    "print(df[\"math_binary\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cacfb93-9b9f-4e3d-bcb1-2229d71dc3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns: ['CNTSTUID', 'W_FSTUWT', 'math_1', 'math_2', 'math_3', 'math_4', 'math_5', 'math_6', 'math_7', 'math_8', 'math_9', 'math_10', 'read_1', 'read_2', 'read_3', 'read_4', 'read_5', 'read_6', 'read_7', 'read_8', 'read_9', 'read_10', 'scie_1', 'scie_2', 'scie_3', 'scie_4', 'scie_5', 'scie_6', 'scie_7', 'scie_8', 'scie_9', 'scie_10', 'gender', 'life_sat', 'emo_control', 'not_distract', 'curiosity', 'comfort_lead', 'math_hwork', 'math_effort', 'math_conf', 'expt_bach', 'conf_self_mot', 'SES', 'num_sib', 'food_sec', 'family_stat', 'parent_talk_schl', 'parent_eat_with', 'has_computer', 'has_books', 'schl_belong', 'teach_respect', 'teac_interest', 'listen_teacher', 'teacher_explain', 'teacher_help', 'safe_student', 'safe_class', 'qual_math_instruct', 'make_friends', 'feel_included', 'no_mock', 'trust_friends', 'trust_gen', 'region', 'math_binary']\n"
     ]
    }
   ],
   "source": [
    "print(\"Renamed columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a6db5e-a1b4-468e-bcf4-a6f703b126e7",
   "metadata": {},
   "source": [
    "##Â 4. Check Missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d814e67-0b85-4562-ad08-49fefb88cb89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conf_self_mot         63.737280\n",
       "parent_talk_schl      61.941104\n",
       "parent_eat_with       61.856306\n",
       "comfort_lead          58.872957\n",
       "not_distract          58.271662\n",
       "trust_friends         58.240826\n",
       "trust_gen             58.171446\n",
       "emo_control           57.747456\n",
       "curiosity             57.469935\n",
       "teacher_explain       56.945729\n",
       "math_effort           56.699044\n",
       "expt_bach             54.486586\n",
       "teach_respect         46.068455\n",
       "teac_interest         45.490287\n",
       "listen_teacher        40.679926\n",
       "math_conf             35.368486\n",
       "schl_belong           28.314832\n",
       "make_friends          27.952513\n",
       "math_hwork            18.902251\n",
       "teacher_help          18.239285\n",
       "qual_math_instruct    16.412273\n",
       "family_stat           14.909035\n",
       "SES                   14.554425\n",
       "no_mock               14.199815\n",
       "safe_student          14.161270\n",
       "feel_included         14.053346\n",
       "safe_class            13.166821\n",
       "life_sat              13.120567\n",
       "food_sec              13.120567\n",
       "has_computer          12.604070\n",
       "has_books             11.971940\n",
       "num_sib               11.794635\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of missing values\n",
    "missing_percent = df.isna().mean() * 100\n",
    "missing_percent[missing_percent > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35316d9f-c28f-4f67-96cd-f6475fc598ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 12972\n",
      "Rows after dropping:  0\n",
      "Percentage kept:      0.00%\n"
     ]
    }
   ],
   "source": [
    "#check how many rows would be left if dropped all missing \n",
    "df_dropped = df.dropna()\n",
    "print(f\"Rows before dropping: {len(df)}\")\n",
    "print(f\"Rows after dropping:  {len(df_dropped)}\")\n",
    "print(f\"Percentage kept:      {len(df_dropped) / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2389e83-87fa-46ae-9cbf-003e673b759d",
   "metadata": {},
   "source": [
    "#### drop anythign with more than 30% missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6eb6e9-30ad-40c3-9727-57956cf05733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dropped 16 columns with >30% missing\n"
     ]
    }
   ],
   "source": [
    "to_drop = missing_percent[missing_percent > 30].index.tolist()\n",
    "df.drop(columns=to_drop, inplace=True)\n",
    "print(f\" Dropped {len(to_drop)} columns with >30% missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a1ca058-1d71-4e26-9dda-1823a52f0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### drop rows with missing target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6cfa169-9d2c-480a-ab9e-f517d95d02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"math_1\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64113ea5-5a46-4972-a018-164e0a913530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Remaining columns by category:\n",
      "\n",
      "ðŸ“‚ Individual:\n",
      "   - gender\n",
      "   - life_sat\n",
      "\n",
      "ðŸ“‚ Academic:\n",
      "   - math_hwork\n",
      "\n",
      "ðŸ“‚ Family:\n",
      "   - SES\n",
      "   - num_sib\n",
      "   - food_sec\n",
      "   - family_stat\n",
      "   - has_computer\n",
      "   - has_books\n",
      "\n",
      "ðŸ“‚ School:\n",
      "   - schl_belong\n",
      "   - teacher_help\n",
      "   - safe_student\n",
      "   - safe_class\n",
      "   - qual_math_instruct\n",
      "\n",
      "ðŸ“‚ Peer/Social:\n",
      "   - make_friends\n",
      "   - feel_included\n",
      "   - no_mock\n",
      "\n",
      "ðŸ“‚ Contextual:\n",
      "   - region\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define original columns grouped by category\n",
    "categories = {\n",
    "    \"Individual\": [\n",
    "        \"gender\", \"life_sat\", \"emo_control\", \"not_distract\", \"curiosity\", \"comfort_lead\"\n",
    "    ],\n",
    "    \"Academic\": [\n",
    "        \"math_hwork\", \"math_effort\", \"math_conf\", \"expt_bach\", \"conf_self_mot\"\n",
    "    ],\n",
    "    \"Family\": [\n",
    "        \"SES\", \"num_sib\", \"food_sec\", \"family_stat\", \"parent_talk_schl\", \"parent_eat_with\", \"has_computer\", \"has_books\"\n",
    "    ],\n",
    "    \"School\": [\n",
    "        \"schl_belong\", \"teach_respect\", \"teac_interest\", \"listen_teacher\",\n",
    "        \"teacher_explain\", \"teacher_help\", \"safe_student\", \"safe_class\", \"qual_math_instruct\"\n",
    "    ],\n",
    "    \"Peer/Social\": [\n",
    "        \"make_friends\", \"feel_included\", \"no_mock\", \"trust_friends\", \"trust_gen\"\n",
    "    ],\n",
    "    \"Contextual\": [\n",
    "        \"region\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Filter only those that remain in the dataframe\n",
    "print(\"\\nâœ… Remaining columns by category:\\n\")\n",
    "for category, vars in categories.items():\n",
    "    kept = [var for var in vars if var in df.columns]\n",
    "    if kept:\n",
    "        print(f\"ðŸ“‚ {category}:\")\n",
    "        for col in kept:\n",
    "            print(f\"   - {col}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd187c5-7725-4e43-baf7-ce552bc78776",
   "metadata": {},
   "source": [
    "# 5.Â Data Splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ca37a6c-9867-4fe2-a62e-b0586934c6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Features \n",
    "selected_features = [\n",
    "    # Individual\n",
    "    \"gender\", \"life_sat\",\n",
    "    # Academic\n",
    "    \"math_hwork\",\n",
    "    # Family\n",
    "    \"SES\", \"num_sib\", \"food_sec\", \"family_stat\", \"has_computer\", \"has_books\",\n",
    "    # School\n",
    "    \"schl_belong\", \"teacher_help\", \"safe_student\", \"safe_class\", \"qual_math_instruct\",\n",
    "    # Peer/Social\n",
    "    \"make_friends\", \"feel_included\", \"no_mock\",\n",
    "    # Contextual\n",
    "    \"region\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "796bdbda-1993-4eb9-b696-b79f0238e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = {\n",
    "    # Individual\n",
    "    \"gender\": \"binary\",\n",
    "    \"life_sat\": \"ordinal\",\n",
    "\n",
    "    # Academic\n",
    "    \"math_hwork\": \"ordinal\",\n",
    "\n",
    "    # Family\n",
    "    \"SES\": \"continuous\",\n",
    "    \"num_sib\": \"discrete\",\n",
    "    \"food_sec\": \"ordinal\",\n",
    "    \"family_stat\": \"continuous\",\n",
    "    \"has_computer\": \"binary\",\n",
    "    \"has_books\": \"binary\",\n",
    "\n",
    "    # School\n",
    "    \"schl_belong\": \"ordinal\",\n",
    "    \"teacher_help\": \"ordinal\",\n",
    "    \"safe_student\": \"ordinal\",\n",
    "    \"safe_class\": \"ordinal\",\n",
    "    \"qual_math_instruct\": \"ordinal\",\n",
    "\n",
    "    # Peer/Social\n",
    "    \"make_friends\": \"ordinal\",\n",
    "    \"feel_included\": \"ordinal\",\n",
    "    \"no_mock\": \"ordinal\",\n",
    "\n",
    "    # Contextual\n",
    "    \"region\": \"categorical\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ab3797-df22-4339-aa23-04eb18efabcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Target \n",
    "target_col = \"math_binary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "003e13a5-d88e-4db1-8f36-a383d8421e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights\n",
    "weights = df[\"W_FSTUWT\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634524ad-b741-41df-a82e-b6368abdb5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X, y, w\n",
    "X = df[selected_features].copy()\n",
    "y = df[target_col].copy()\n",
    "w = weights.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "585d2672-66e6-4535-98bb-b4109406d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train / temp\n",
    "X_temp, X_test, y_temp, y_test, w_temp, w_test = train_test_split(\n",
    "    X, y, w, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efc3fd58-7f5e-43e9-8956-4f66af507d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train / val\n",
    "X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(\n",
    "    X_temp, y_temp, w_temp, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6edda69-fea7-4c48-a003-0091053fbd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:   (7782, 18)\n",
      "Validation: (2595, 18)\n",
      "Test:       (2595, 18)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training:   {X_train.shape}\")\n",
    "print(f\"Validation: {X_val.shape}\")\n",
    "print(f\"Test:       {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b754f14-b00f-4f33-93e7-5ec22e323c1d",
   "metadata": {},
   "source": [
    "# 6. Missing Data Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f55f65-60fd-438a-a6c7-4ab3bf976e9c",
   "metadata": {},
   "source": [
    "##### I am using simple imputation because it is fast, effective, and well-suited for decision trees. \n",
    "- Median imputation for all numeric features\n",
    "- Mode imputation for the two binary categorical ones (has_computer, has_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "328478b8-b56e-4eb6-8a50-e15ec900b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing(df, name):\n",
    "    print(f\"\\nðŸ“Š Missing value summary: {name}\")\n",
    "    missing = df.isna().sum()\n",
    "    percent = df.isna().mean() * 100\n",
    "    summary = pd.DataFrame({'Missing': missing, 'Percent': percent})\n",
    "    summary = summary[summary['Missing'] > 0].sort_values('Percent', ascending=False)\n",
    "    if summary.empty:\n",
    "        print(\"âœ… No missing values.\")\n",
    "    else:\n",
    "        print(summary.round(2))\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "371bf341-8d90-40cd-8cbf-878847a43da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Missing value summary: Train\n",
      "                    Missing  Percent\n",
      "schl_belong            2234    28.71\n",
      "make_friends           2185    28.08\n",
      "math_hwork             1483    19.06\n",
      "teacher_help           1443    18.54\n",
      "qual_math_instruct     1290    16.58\n",
      "family_stat            1165    14.97\n",
      "SES                    1147    14.74\n",
      "no_mock                1108    14.24\n",
      "safe_student           1106    14.21\n",
      "feel_included          1096    14.08\n",
      "life_sat               1043    13.40\n",
      "food_sec               1034    13.29\n",
      "safe_class             1018    13.08\n",
      "has_computer            976    12.54\n",
      "has_books               933    11.99\n",
      "num_sib                 927    11.91\n",
      "\n",
      "ðŸ“Š Missing value summary: Validation\n",
      "                    Missing  Percent\n",
      "make_friends            726    27.98\n",
      "schl_belong             707    27.24\n",
      "math_hwork              490    18.88\n",
      "teacher_help            454    17.50\n",
      "qual_math_instruct      421    16.22\n",
      "family_stat             372    14.34\n",
      "no_mock                 364    14.03\n",
      "SES                     359    13.83\n",
      "safe_student            358    13.80\n",
      "feel_included           354    13.64\n",
      "safe_class              334    12.87\n",
      "food_sec                329    12.68\n",
      "has_computer            325    12.52\n",
      "life_sat                324    12.49\n",
      "has_books               301    11.60\n",
      "num_sib                 298    11.48\n",
      "\n",
      "ðŸ“Š Missing value summary: Test\n",
      "                    Missing  Percent\n",
      "schl_belong             732    28.21\n",
      "make_friends            715    27.55\n",
      "math_hwork              479    18.46\n",
      "teacher_help            469    18.07\n",
      "qual_math_instruct      418    16.11\n",
      "family_stat             397    15.30\n",
      "SES                     382    14.72\n",
      "feel_included           373    14.37\n",
      "safe_student            373    14.37\n",
      "no_mock                 370    14.26\n",
      "safe_class              356    13.72\n",
      "food_sec                339    13.06\n",
      "life_sat                335    12.91\n",
      "has_computer            334    12.87\n",
      "has_books               319    12.29\n",
      "num_sib                 305    11.75\n"
     ]
    }
   ],
   "source": [
    "train_missing = analyze_missing(X_train, \"Train\")\n",
    "val_missing = analyze_missing(X_val, \"Validation\")\n",
    "test_missing = analyze_missing(X_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e80b491e-c44b-4554-bd12-03720d93228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define categorical and numeric cols\n",
    "categorical_cols = [\"has_computer\", \"has_books\", \"region\"]\n",
    "\n",
    "# Define numeric columns by checking actual dtypes in the dataframe\n",
    "numeric_cols = [col for col in X_train.columns if col not in categorical_cols + [\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10fb7cdb-46d9-4ce9-a67a-7077315babb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in categorical (binary) columns:\n",
      "has_computer    976\n",
      "has_books       933\n",
      "region            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in numeric columns:\n",
      "gender                   0\n",
      "life_sat              1043\n",
      "math_hwork            1483\n",
      "SES                   1147\n",
      "num_sib                927\n",
      "food_sec              1034\n",
      "family_stat           1165\n",
      "schl_belong           2234\n",
      "teacher_help          1443\n",
      "safe_student          1106\n",
      "safe_class            1018\n",
      "qual_math_instruct    1290\n",
      "make_friends          2185\n",
      "feel_included         1096\n",
      "no_mock               1108\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in categorical (binary) columns:\")\n",
    "print(X_train[categorical_cols].isna().sum())\n",
    "\n",
    "print(\"\\nMissing values in numeric columns:\")\n",
    "print(X_train[numeric_cols].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4aaffba-f876-432d-9bd2-828ac8b4c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clean working copies\n",
    "X_train = X_train.copy()\n",
    "X_val = X_val.copy()\n",
    "X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b09ef42c-802a-47a7-a568-f0dc88fdbd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation for numeric\n",
    "num_imputer = SimpleImputer(strategy=\"median\")\n",
    "X_train[numeric_cols] = num_imputer.fit_transform(X_train[numeric_cols])\n",
    "X_val[numeric_cols] = num_imputer.transform(X_val[numeric_cols])\n",
    "X_test[numeric_cols] = num_imputer.transform(X_test[numeric_cols])\n",
    "\n",
    "# Mode imputation for binary categorical\n",
    "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "X_train[categorical_cols] = cat_imputer.fit_transform(X_train[categorical_cols])\n",
    "X_val[categorical_cols] = cat_imputer.transform(X_val[categorical_cols])\n",
    "X_test[categorical_cols] = cat_imputer.transform(X_test[categorical_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d44bf4c-5cd2-4d33-895b-00260169cc4a",
   "metadata": {},
   "source": [
    "# 7. One-Hot Encode \"region\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd5f2916-95b0-41b9-8ab2-204c2cfb4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode region in train, val, test\n",
    "X_train = pd.get_dummies(X_train, columns=[\"region\"])\n",
    "X_val = pd.get_dummies(X_val, columns=[\"region\"])\n",
    "X_test = pd.get_dummies(X_test, columns=[\"region\"])\n",
    "\n",
    "# Align columns across splits (to ensure same dummy variables exist)\n",
    "X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "categorical_cols = [col for col in X_train.columns if col.startswith(\"region_\") or col in [\"has_computer\", \"has_books\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7166dbc1-fa7c-45ca-8201-62fe50257611",
   "metadata": {},
   "source": [
    "# 8. Save to CSV with weights included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0204ba07-88de-46b5-ae54-f03be66ce296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add target and weights to each dataset\n",
    "X_train[\"target\"] = y_train\n",
    "X_train[\"sample_weight\"] = w_train\n",
    "\n",
    "X_val[\"target\"] = y_val\n",
    "X_val[\"sample_weight\"] = w_val\n",
    "\n",
    "X_test[\"target\"] = y_test\n",
    "X_test[\"sample_weight\"] = w_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0b94343-0dbf-4c0a-bd36-267d5581222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv(\"/workspaces/mini_project_2/data/processed/train.csv\", index=False)\n",
    "X_val.to_csv(\"/workspaces/mini_project_2/data/processed/val.csv\", index=False)\n",
    "X_test.to_csv(\"/workspaces/mini_project_2/data/processed/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "035171c0-1b2d-48bf-9a36-26855f0d0a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessing complete. Data saved to /data/processed/\n",
      "Train shape: (7782, 23)\n",
      "Validation shape: (2595, 23)\n",
      "Test shape: (2595, 23)\n"
     ]
    }
   ],
   "source": [
    "X_train[\"target\"] = y_train\n",
    "X_val[\"target\"] = y_val\n",
    "X_test[\"target\"] = y_test\n",
    "\n",
    "X_train.to_csv(\"/workspaces/mini_project_2/data/processed/train.csv\", index=False)\n",
    "X_val.to_csv(\"/workspaces/mini_project_2/data/processed/val.csv\", index=False)\n",
    "X_test.to_csv(\"/workspaces/mini_project_2/data/processed/test.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Preprocessing complete. Data saved to /data/processed/\")\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acd6d23c-d33c-4b18-9e34-fcd2d1c4623c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       gender  life_sat  math_hwork     SES  num_sib  food_sec  family_stat  \\\n",
      "7371      0.0       4.0         1.0 -0.8355      4.0       3.0          4.0   \n",
      "8058      0.0       7.0         1.0  0.1750      3.0       5.0          7.0   \n",
      "12177     0.0       9.0         1.0 -0.5774      4.0       5.0          9.0   \n",
      "4729      0.0       5.0         1.0 -0.3974      3.0       5.0          7.0   \n",
      "1475      1.0       7.0         1.0  0.1750      3.0       5.0          7.0   \n",
      "\n",
      "      has_computer has_books  schl_belong  ...  qual_math_instruct  \\\n",
      "7371           0.0       1.0          3.0  ...                 4.0   \n",
      "8058           1.0       0.0          3.0  ...                 7.0   \n",
      "12177          1.0       0.0          3.0  ...                 6.0   \n",
      "4729           1.0       0.0          3.0  ...                 9.0   \n",
      "1475           1.0       0.0          3.0  ...                 7.0   \n",
      "\n",
      "       make_friends  feel_included  no_mock  region_england  region_n_ireland  \\\n",
      "7371            2.0            4.0      4.0           False             False   \n",
      "8058            3.0            4.0      4.0            True             False   \n",
      "12177           3.0            3.0      1.0           False             False   \n",
      "4729            3.0            4.0      4.0           False              True   \n",
      "1475            3.0            4.0      4.0            True             False   \n",
      "\n",
      "       region_scotland  region_wales  target  sample_weight  \n",
      "7371             False          True       0        8.91569  \n",
      "8058             False         False       1      134.23770  \n",
      "12177             True         False       0       16.64343  \n",
      "4729             False         False       0        9.13905  \n",
      "1475             False         False       0      126.34970  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028e6775-b63c-4ba5-81fa-02f3d6dd0d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
